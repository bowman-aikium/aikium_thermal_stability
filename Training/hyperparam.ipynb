{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "409226d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import from your Model folder\n",
    "from Model.model import thermalMLP, ProteinTmDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0bd6c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>embedding</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>From</th>\n",
       "      <th>AA_length</th>\n",
       "      <th>MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117012</td>\n",
       "      <td>[3.4952238, 2.9369724, -3.406106, -1.0034976, ...</td>\n",
       "      <td>45.556042</td>\n",
       "      <td>MKWAYKEENNFEKRRAEGDKIRRKYPDRIPVIVEKAPKSKLHDLDK...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>123</td>\n",
       "      <td>14.763731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313786</td>\n",
       "      <td>[2.2217994, -2.0552912, -0.14634663, 1.3754547...</td>\n",
       "      <td>43.863329</td>\n",
       "      <td>MVKATNVDLSLEDIISKTRKTTGSIQKKSFGGARRGNTRPTGLPRR...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>240</td>\n",
       "      <td>25.695370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169171</td>\n",
       "      <td>[3.0030677, 4.205013, 4.074065, 0.7811, -6.895...</td>\n",
       "      <td>43.574470</td>\n",
       "      <td>MPRANEIKKGMVLNYNGKLLLVKDIDIQSPTARGAATLYKMRFSDV...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>190</td>\n",
       "      <td>21.532381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227821</td>\n",
       "      <td>[4.7244706, -0.123155594, 1.057647, 4.5875287,...</td>\n",
       "      <td>40.496359</td>\n",
       "      <td>MTKSELIERMLTKQPQLSAKDVELAVKTILDHMSQSLSTGERIEIR...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>96</td>\n",
       "      <td>10.757199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97927</td>\n",
       "      <td>[2.16275, -1.2902148, 2.1692014, 0.009807652, ...</td>\n",
       "      <td>37.073883</td>\n",
       "      <td>MRQVVLDTETTGIGAEKGHRIIEIGCVELIDRKLTGRHYHQYVNPQ...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>234</td>\n",
       "      <td>26.063256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>200713</td>\n",
       "      <td>[3.211512, 0.9198779, -0.08337058, -1.2356853,...</td>\n",
       "      <td>86.289547</td>\n",
       "      <td>MTVRQVLVHKGGGVHAIHPEATVLDALRKLAEHDIGALLVMEGERL...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>143</td>\n",
       "      <td>15.916415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>267005</td>\n",
       "      <td>[-1.4136505, -2.4800174, 0.06798242, 2.689519,...</td>\n",
       "      <td>88.057949</td>\n",
       "      <td>MTGLELLAVALGMRHGVDPDHLAAVDGLSRVRPSPLNGVLFALGHG...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>220</td>\n",
       "      <td>22.874996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>269836</td>\n",
       "      <td>[2.5266905, -5.975683, -3.1002605, 1.2522675, ...</td>\n",
       "      <td>88.583454</td>\n",
       "      <td>MASLSFMIKEYNDYYIIDFERPVRKFSSAPFNGGVGTSLRYINRTV...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>215</td>\n",
       "      <td>24.262483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>298355</td>\n",
       "      <td>[0.30273947, 2.1589444, -0.4573475, -0.4192088...</td>\n",
       "      <td>86.755190</td>\n",
       "      <td>MRFKAELMNAPEMRRALYRIAHEIVEANKGTEGLALVGIHTRGIPL...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>181</td>\n",
       "      <td>20.466363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>37198</td>\n",
       "      <td>[0.4684455, 2.357703, 1.3999882, -4.0473776, 0...</td>\n",
       "      <td>93.243683</td>\n",
       "      <td>MWIYGRNPVLEALRAGRARRVLVARGVEGWLLKELERLGAPYTLVP...</td>\n",
       "      <td>meltome</td>\n",
       "      <td>238</td>\n",
       "      <td>26.029972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23420 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                          embedding         Tm  \\\n",
       "0      117012  [3.4952238, 2.9369724, -3.406106, -1.0034976, ...  45.556042   \n",
       "1      313786  [2.2217994, -2.0552912, -0.14634663, 1.3754547...  43.863329   \n",
       "2      169171  [3.0030677, 4.205013, 4.074065, 0.7811, -6.895...  43.574470   \n",
       "3      227821  [4.7244706, -0.123155594, 1.057647, 4.5875287,...  40.496359   \n",
       "4       97927  [2.16275, -1.2902148, 2.1692014, 0.009807652, ...  37.073883   \n",
       "...       ...                                                ...        ...   \n",
       "23415  200713  [3.211512, 0.9198779, -0.08337058, -1.2356853,...  86.289547   \n",
       "23416  267005  [-1.4136505, -2.4800174, 0.06798242, 2.689519,...  88.057949   \n",
       "23417  269836  [2.5266905, -5.975683, -3.1002605, 1.2522675, ...  88.583454   \n",
       "23418  298355  [0.30273947, 2.1589444, -0.4573475, -0.4192088...  86.755190   \n",
       "23419   37198  [0.4684455, 2.357703, 1.3999882, -4.0473776, 0...  93.243683   \n",
       "\n",
       "                                                Sequence     From  AA_length  \\\n",
       "0      MKWAYKEENNFEKRRAEGDKIRRKYPDRIPVIVEKAPKSKLHDLDK...  meltome        123   \n",
       "1      MVKATNVDLSLEDIISKTRKTTGSIQKKSFGGARRGNTRPTGLPRR...  meltome        240   \n",
       "2      MPRANEIKKGMVLNYNGKLLLVKDIDIQSPTARGAATLYKMRFSDV...  meltome        190   \n",
       "3      MTKSELIERMLTKQPQLSAKDVELAVKTILDHMSQSLSTGERIEIR...  meltome         96   \n",
       "4      MRQVVLDTETTGIGAEKGHRIIEIGCVELIDRKLTGRHYHQYVNPQ...  meltome        234   \n",
       "...                                                  ...      ...        ...   \n",
       "23415  MTVRQVLVHKGGGVHAIHPEATVLDALRKLAEHDIGALLVMEGERL...  meltome        143   \n",
       "23416  MTGLELLAVALGMRHGVDPDHLAAVDGLSRVRPSPLNGVLFALGHG...  meltome        220   \n",
       "23417  MASLSFMIKEYNDYYIIDFERPVRKFSSAPFNGGVGTSLRYINRTV...  meltome        215   \n",
       "23418  MRFKAELMNAPEMRRALYRIAHEIVEANKGTEGLALVGIHTRGIPL...  meltome        181   \n",
       "23419  MWIYGRNPVLEALRAGRARRVLVARGVEGWLLKELERLGAPYTLVP...  meltome        238   \n",
       "\n",
       "              MW  \n",
       "0      14.763731  \n",
       "1      25.695370  \n",
       "2      21.532381  \n",
       "3      10.757199  \n",
       "4      26.063256  \n",
       "...          ...  \n",
       "23415  15.916415  \n",
       "23416  22.874996  \n",
       "23417  24.262483  \n",
       "23418  20.466363  \n",
       "23419  26.029972  \n",
       "\n",
       "[23420 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_np = np.load(\"/Users/aikium_intern/Desktop/aikium_thermal_stability/Data/esm2_embeddings_with_ids.npz\", allow_pickle=True)\n",
    "dataset_df = pd.read_csv(\"/Users/aikium_intern/Desktop/aikium_thermal_stability/Data/Stratified_data.csv\")\n",
    "\n",
    "embedding = embedding_np[\"embeddings\"]   # shape: (N, hidden_dim)\n",
    "ids = embedding_np[\"ids\"]    \n",
    "\n",
    "emb_df = pd.DataFrame({\n",
    "    \"ID\": ids,\n",
    "    \"embedding\": list(embedding)\n",
    "})\n",
    "\n",
    "emb_df[\"ID\"] = emb_df[\"ID\"].astype(int)\n",
    "dataset_df[\"ID\"] = dataset_df[\"ID\"].astype(int)\n",
    "merged = emb_df.merge(dataset_df, on=\"ID\")\n",
    "merged\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d9a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(params, input_dim, train_loader, val_loader):\n",
    "    \n",
    "    model = thermalMLP(\n",
    "        input_dim=input_dim,\n",
    "        hidden_sizes=params[\"hidden_sizes\"],\n",
    "        activation=params[\"activation\"],\n",
    "        dropout=params[\"dropout\"]\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                epoch_val_loss += criterion(preds, yb).item()\n",
    "        val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{params['epochs']} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d71607",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m hyperparam_sweep:\n\u001b[0;32m---> 21\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((params, val_loss))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(preds, yb)\n\u001b[1;32m     18\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bioenv/lib/python3.10/site-packages/torch/optim/adam.py:430\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = np.stack(merged[\"embedding\"].values)\n",
    "Tm = merged[\"Tm\"].values\n",
    "input_dim = embeddings.shape[1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(embeddings, Tm, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = ProteinTmDataset(X_train, y_train)\n",
    "val_ds = ProteinTmDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "\n",
    "# Define search space\n",
    "hyperparam_sweep = [\n",
    "    {\"hidden_sizes\": [64], \"activation\": nn.ReLU, \"dropout\": 0.0, \"lr\": 1e-3, \"epochs\": 10},\n",
    "    {\"hidden_sizes\": [128], \"activation\": nn.ReLU, \"dropout\": 0.0, \"lr\": 1e-3, \"epochs\": 10},\n",
    "    {\"hidden_sizes\": [256, 128], \"activation\": nn.ReLU, \"dropout\": 0.2, \"lr\": 1e-3, \"epochs\": 10},\n",
    "    {\"hidden_sizes\": [512, 256], \"activation\": nn.ReLU, \"dropout\": 0.2, \"lr\": 1e-3, \"epochs\": 10},\n",
    "    {\"hidden_sizes\": [512, 256, 128], \"activation\": nn.ReLU, \"dropout\": 0.3, \"lr\": 5e-4, \"epochs\": 15},\n",
    "    {\"hidden_sizes\": [1024, 512, 256], \"activation\": nn.ReLU, \"dropout\": 0.3, \"lr\": 5e-4, \"epochs\": 15},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i, params in enumerate(hyperparam_sweep):\n",
    "    train_loss, val_loss = train_and_eval(params, input_dim, train_loader, val_loader)\n",
    "    results.append((params, train_loss, val_loss))\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label=\"Train Loss\")\n",
    "    plt.plot(val_loss, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(f\"Training vs Validation Loss\\nConfig {i+1}: {params['hidden_sizes']}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Show best\n",
    "best = sorted(results, key=lambda x: x[2][-1])[0]\n",
    "print(\"\\nBest config:\", best[0], \"| Final Val Loss:\", best[2][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
